y <- ifelse(a == 1, y1, y0)
# Average treatment effect is equal to total effect of Ey1 - Ey0 = 4 + Ec1 - (2 + Ec2) = 4 - 2  = 2
mean(y1) - mean(y0)
# Author: Juha Karvanen/code: Tetiana Gorbach
# Date: 2024-05-17
# This code presents an example of a DAg with a trpdoor variable
# Load required library
library(mvtnorm)
library(bnlearn)
# Generate data -----------------------------------------------------------
# Set a seed for reproducibility
set.seed(29111)
# Set the sample size
n <- 1000000
# Define confounders c1, c2 with a deterministic relationship
errors <- rmvnorm(n, sigma = diag(4))
# Generate confounders
u1 <- rnorm(n)
u2 <-  rnorm(n)
c1 <- 3 + u1 +  errors[, 1]
c2 <- 1 + u1 +  c1 + errors[, 2]
# Generate binary treatment that depends on c2
a <- rbinom(n, size = 1, prob = plogis(c1 + c2 + u))
# Author: Juha Karvanen/code: Tetiana Gorbach
# Date: 2024-05-17
# This code presents an example of a DAg with a trpdoor variable
# Load required library
library(mvtnorm)
library(bnlearn)
# Generate data -----------------------------------------------------------
# Set a seed for reproducibility
set.seed(29111)
# Set the sample size
n <- 1000000
# Define confounders c1, c2 with a deterministic relationship
errors <- rmvnorm(n, sigma = diag(4))
# Generate confounders
u1 <- rnorm(n)
u2 <-  rnorm(n)
c1 <- 3 + u1 +  errors[, 1]
c2 <- 1 + u1 +  c1 + errors[, 2]
# Generate binary treatment that depends on c2
a <- rbinom(n, size = 1, prob = plogis(c1 + c2 + u1))
# Generate potential outcomes
y1 <- 4 + c1 + u2 + errors[, 3]
y0 <- 2 + c1 + u2 + errors[, 4]
# Generate observed outcome
y <- ifelse(a == 1, y1, y0)
# Average treatment effect is equal to total effect of Ey1 - Ey0 = 4 + Ec1 - (2 + Ec2) = 4 - 2  = 2
mean(y1) - mean(y0)
# Check ignorability ------------------------------------------------------
ci.test(y0, as.numeric(a), data.frame(c1, c2)) # y0 is independent of a given c1, c2: weak unconfoundedness is fulfilled
ci.test(y1, as.numeric(a), data.frame(c1, c2)) # y1 is independent of a given c1, c2: weak unconfoundedness is fulfilled
library(mvtnorm)
library(bnlearn)
# Generate data -----------------------------------------------------------
# Set a seed for reproducibility
set.seed(29111)
# Set the sample size
n <- 1000000
# Define confounders c1, c2 with a deterministic relationship
errors <- rmvnorm(n, sigma = diag(4))
# Generate confounders
u1 <- rnorm(n)
u2 <-  rnorm(n)
c1 <- 3 + u1 + u2 +   errors[, 1]
c2 <- 1 + u1 +  c1 + errors[, 2]
# Generate binary treatment that depends on c2
a <- rbinom(n, size = 1, prob = plogis(c1 + c2 + u1))
# Generate potential outcomes
y1 <- 4 + c1 + u2 + errors[, 3]
y0 <- 2 + c1 + u2 + errors[, 4]
# Generate observed outcome
y <- ifelse(a == 1, y1, y0)
# Average treatment effect is equal to total effect of Ey1 - Ey0 = 4 + Ec1 - (2 + Ec2) = 4 - 2  = 2
mean(y1) - mean(y0)
# Check ignorability ------------------------------------------------------
ci.test(y0, as.numeric(a), data.frame(c1, c2)) # y0 is independent of a given c1, c2: weak unconfoundedness is fulfilled
ci.test(y1, as.numeric(a), data.frame(c1, c2)) # y1 is independent of a given c1, c2: weak unconfoundedness is fulfilled
# Average causal effect can be consistently estimated by a linear regression: --------
lm(y ~ a + c1 + c2)
hist(c1)
# Author: Juha Karvanen/code: Tetiana Gorbach
# Date: 2024-05-17
# This code presents an example of a DAg with a trpdoor variable
# Load required library
library(mvtnorm)
library(bnlearn)
# Generate data -----------------------------------------------------------
# Set a seed for reproducibility
set.seed(29111)
# Set the sample size
n <- 1000000
# Define confounders c1, c2 with a deterministic relationship
errors <- rmvnorm(n, sigma = diag(4))
# Generate confounders
u1 <- rnorm(n)
u2 <-  rnorm(n)
c1 <- rbinom(n, size = 1, prob = plogis(3 + u1 + u2)) #3 + u1 + u2 +   errors[, 1]
c2 <- rbinom(n, size = 1, prob = plogis(1 + u1 +  c1)) # 1 + u1 +  c1 + errors[, 2]
# Generate binary treatment that depends on c2
a <- rbinom(n, size = 1, prob = plogis(c1 + c2 + u1))
# Generate potential outcomes
y1 <- 4 + c1 + u2 + errors[, 3]
y0 <- 2 + c1 + u2 + errors[, 4]
# Generate observed outcome
y <- ifelse(a == 1, y1, y0)
# Average treatment effect is equal to total effect of Ey1 - Ey0 = 4 + Ec1 - (2 + Ec2) = 4 - 2  = 2
mean(y1) - mean(y0)
# Check ignorability ------------------------------------------------------
ci.test(y0, as.numeric(a), data.frame(c1, c2)) # y0 is independent of a given c1, c2: weak unconfoundedness is fulfilled
# Author: Juha Karvanen/code: Tetiana Gorbach
# Date: 2024-05-17
# This code presents an example of a DAg with a trpdoor variable
# Load required library
library(mvtnorm)
library(bnlearn)
# Generate data -----------------------------------------------------------
# Set a seed for reproducibility
set.seed(29111)
# Set the sample size
n <- 1000000
# Define confounders c1, c2 with a deterministic relationship
errors <- rmvnorm(n, sigma = diag(4))
# Generate confounders
u1 <- rnorm(n)
u2 <-  rnorm(n)
c1 <- rbinom(n, size = 1, prob = plogis(3 + u1 + u2)) #3 + u1 + u2 +   errors[, 1]
c2 <- rbinom(n, size = 1, prob = plogis(1 + u1 +  c1)) # 1 + u1 +  c1 + errors[, 2]
# Generate binary treatment that depends on c2
a <- rbinom(n, size = 1, prob = plogis(c1 + c2 + u1))
# Generate potential outcomes
y1 <- 4 + c1 + u2 + errors[, 3]
y0 <- 2 + c1 + u2 + errors[, 4]
# Generate observed outcome
y <- ifelse(a == 1, y1, y0)
# Average treatment effect is equal to total effect of Ey1 - Ey0 = 4 + Ec1 - (2 + Ec2) = 4 - 2  = 2
mean(y1) - mean(y0)
# Check ignorability ------------------------------------------------------
ci.test(y0, as.numeric(a), data.frame(c1, c2)) # y0 is independent of a given c1, c2: weak unconfoundedness is fulfilled
# Check ignorability ------------------------------------------------------
ci.test(y0, as.numeric(a), data.frame(as.numeric(c1), as.numeric(c2))) # y0 is independent of a given c1, c2: weak unconfoundedness is fulfilled
ci.test(y1, as.numeric(a), data.frame(as.numeric(c1), as.numeric(c2))) # y1 is dependent on a given c1, c2: weak unconfoundedness is fulfilled
# Average causal effect can be consistently estimated by a linear regression: --------
lm(y ~ a + c1 + c2)
styler:::style_selection()
# ATE estimate using the identification
(mean(y[c1 == 0 & c2 == 1 & a == 1]) * mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 1 & a == 1]) * mean(a[c1 == 1 & c2 == 1]) * mean(c1)) /
(mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) + mean(a[c1 == 1 & c2 == 1]) * mean(c1))
(mean(y[c1 == 0 & c2 == 1 & a == 1]) * mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 1 & a == 1]) * mean(a[c1 == 1 & c2 == 1]) * mean(c1))
(mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) + mean(a[c1 == 1 & c2 == 1]) * mean(c1))
# Average treatment effect is equal to total effect of Ey1 - Ey0 = 4 + Ec1 - (2 + Ec2) = 4 - 2  = 2
mean(y1) - mean(y0)
mean(y1)
# Average causal effect can be consistently estimated by a linear regression: --------
lm(y ~ a + c1 + c2)
# EY(0)
mean(y0)
# EY(0) estimate using the identification
(mean(y[c1 == 0 & c2 == 1 & a == 0]) * mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 1 & a == 0]) * mean(a[c1 == 1 & c2 == 1]) * mean(c1)) /
(mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) + mean(a[c1 == 1 & c2 == 1]) * mean(c1))
# Author: Juha Karvanen/code: Tetiana Gorbach
# Date: 2024-05-17
# This code presents an example of a DAg with a trpdoor variable
# Load required library
library(mvtnorm)
library(bnlearn)
# Generate data -----------------------------------------------------------
# Set a seed for reproducibility
set.seed(29111)
# Set the sample size
n <- 10000000
# Define confounders c1, c2 with a deterministic relationship
errors <- rmvnorm(n, sigma = diag(4))
# Generate confounders
u1 <- rnorm(n)
u2 <-  rnorm(n)
c1 <- rbinom(n, size = 1, prob = plogis(3 + u1 + u2)) #3 + u1 + u2 +   errors[, 1]
c2 <- rbinom(n, size = 1, prob = plogis(1 + u1 +  c1)) # 1 + u1 +  c1 + errors[, 2]
# Generate binary treatment that depends on c2
a <- rbinom(n, size = 1, prob = plogis(c1 + c2 + u1))
# Generate potential outcomes
y1 <- 4 + c1 + u2 + errors[, 3]
y0 <- 2 + c1 + u2 + errors[, 4]
# Generate observed outcome
y <- ifelse(a == 1, y1, y0)
# EY(1)
mean(y1)
# EY(1) estimate using the identification
(mean(y[c1 == 0 & c2 == 1 & a == 1]) * mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 1 & a == 1]) * mean(a[c1 == 1 & c2 == 1]) * mean(c1)) /
(mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) + mean(a[c1 == 1 & c2 == 1]) * mean(c1))
# EY(0)
mean(y0)
# EY(0) estimate using the identification
(mean(y[c1 == 0 & c2 == 1 & a == 0]) * mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 1 & a == 0]) * mean(a[c1 == 1 & c2 == 1]) * mean(c1)) /
(mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) + mean(a[c1 == 1 & c2 == 1]) * mean(c1))
(mean(y[c1 == 0 & c2 == 0 & a == 0]) * mean(a[c1 == 0 & c2 == 0]) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 0 & a == 0]) * mean(a[c1 == 1 & c2 == 0]) * mean(c1)) /
(mean(a[c1 == 0 & c2 == 0]) * (1 - mean(c1)) + mean(a[c1 == 1 & c2 == 0]) * mean(c1))
# Average causal effect estimated through the back-door adjustment
lm(y ~ a + c1 + c2)
# EY(1)
mean(y1)
# EY(1) estimate using the identification
(mean(y[c1 == 0 & c2 == 1 & a == 1]) * mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 1 & a == 1]) * mean(a[c1 == 1 & c2 == 1]) * mean(c1)) /
(mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) + mean(a[c1 == 1 & c2 == 1]) * mean(c1))
# Author: Juha Karvanen/code: Tetiana Gorbach
# Date: 2024-05-17
# This code presents an example of a DAg with a trpdoor variable
# Load required library
library(mvtnorm)
library(bnlearn)
# Generate data -----------------------------------------------------------
# Set a seed for reproducibility
set.seed(29111)
# Set the sample size
n <- 1000000
# Define confounders c1, c2 with a deterministic relationship
errors <- rmvnorm(n, sigma = diag(4))
# Generate confounders
u1 <- rnorm(n)
u2 <-  rnorm(n)
c1 <- rbinom(n, size = 1, prob = plogis(3 + u1 + u2)) #3 + u1 + u2 +   errors[, 1]
c2 <- rbinom(n, size = 1, prob = plogis(1 + u1 +  c1)) # 1 + u1 +  c1 + errors[, 2]
# Generate binary treatment that depends on c2
a <- rbinom(n, size = 1, prob = plogis(c1 + c2 + u1))
# Generate potential outcomes
y1 <- 4 + c1 + u2 + errors[, 3]
y0 <- 2 + c1 + u2 + errors[, 4]
# Generate observed outcome
y <- ifelse(a == 1, y1, y0)
# EY(1)
mean(y1)
# EY(1) estimate using the identification
(mean(y[c1 == 0 & c2 == 1 & a == 1]) * mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 1 & a == 1]) * mean(a[c1 == 1 & c2 == 1]) * mean(c1)) /
(mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) + mean(a[c1 == 1 & c2 == 1]) * mean(c1))
# EY(0)
mean(y0)
# EY(0) estimate using the identification
(mean(y[c1 == 0 & c2 == 1 & a == 0]) * mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 1 & a == 0]) * mean(a[c1 == 1 & c2 == 1]) * mean(c1)) /
(mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) + mean(a[c1 == 1 & c2 == 1]) * mean(c1))
(mean(y[c1 == 0 & c2 == 0 & a == 0]) * mean(a[c1 == 0 & c2 == 0]) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 0 & a == 0]) * mean(a[c1 == 1 & c2 == 0]) * mean(c1)) /
(mean(a[c1 == 0 & c2 == 0]) * (1 - mean(c1)) + mean(a[c1 == 1 & c2 == 0]) * mean(c1))
c1 <- rbinom(n, size = 1, prob = 0.4*v + 0.4*w)
v <- rbinom(n , size = 1, p = 0.5)
u <- rbinom(n , size = 1, p = 0.5)
c1 <- rbinom(n, size = 1, prob = 0.4*v + 0.4*w)
# Author: Juha Karvanen/code: Tetiana Gorbach
# Date: 2024-05-17
# This code presents an example of a DAg with a trpdoor variable
# Load required library
library(mvtnorm)
library(bnlearn)
# Generate data -----------------------------------------------------------
# Set a seed for reproducibility
set.seed(29111)
# Set the sample size
n <- 1000000
# Define confounders c1, c2 with a deterministic relationship
errors <- rmvnorm(n, sigma = diag(4))
# Generate confounders
# u1 <- rnorm(n)
# u2 <-  rnorm(n)
# c1 <- rbinom(n, size = 1, prob = plogis(3 + u1 + u2)) #3 + u1 + u2 +   errors[, 1]
# c2 <- rbinom(n, size = 1, prob = plogis(1 + u1 +  c1)) # 1 + u1 +  c1 + errors[, 2]
# # Generate binary treatment that depends on c2
# a <- rbinom(n, size = 1, prob = plogis(c1 + c2 + u1))
#
# # Generate potential outcomes
# y1 <- 4 + c1 + u2 + errors[, 3]
# y0 <- 2 + c1 + u2 + errors[, 4]
v <- rbinom(n , size = 1, p = 0.5)
u <- rbinom(n , size = 1, p = 0.5)
c1 <- rbinom(n, size = 1, prob = 0.4*u + 0.4*v)
c2 <- rbinom(n, size = 1, prob = 0.4 + 0.4*c1)
a <- rbinom(n, size = 1, prob = 0.4*c2 + 0.4*v)
y <- rbinom(n, size = 1, prob = 0.4*a + 0.4*u)
mean(y[a==1])
# EY(1) estimate using the identification
(mean(y[c1 == 0 & c2 == 1 & a == 1]) * mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 1 & a == 1]) * mean(a[c1 == 1 & c2 == 1]) * mean(c1)) /
(mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) + mean(a[c1 == 1 & c2 == 1]) * mean(c1))
v <- rbinom(n , size = 1, p = 0.5)
u <- rbinom(n , size = 1, p = 0.5)
c1 <- rbinom(n, size = 1, prob = 0.4*u + 0.4*v)
c2 <- rbinom(n, size = 1, prob = 0.4 + 0.4*c1)
a <- rbinom(n, size = 1, prob = 0.4*c2 + 0.4*v)
y <- rbinom(n, size = 1, prob = 0.4*a + 0.4*u)
# EY(1)
mean(y[a==1])  # ? is completely correct?
# EY(1) estimate using the identification
(mean(y[c1 == 0 & c2 == 1 & a == 1]) * mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 1 & a == 1]) * mean(a[c1 == 1 & c2 == 1]) * mean(c1)) /
(mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) + mean(a[c1 == 1 & c2 == 1]) * mean(c1))
# EY(0)
mean(y[a==0])
# EY(0) estimate using the identification
(mean(y[c1 == 0 & c2 == 1 & a == 0]) * mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 1 & a == 0]) * mean(a[c1 == 1 & c2 == 1]) * mean(c1)) /
(mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) + mean(a[c1 == 1 & c2 == 1]) * mean(c1))
(mean(y[c1 == 0 & c2 == 0 & a == 0]) * mean(a[c1 == 0 & c2 == 0]) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 0 & a == 0]) * mean(a[c1 == 1 & c2 == 0]) * mean(c1)) /
(mean(a[c1 == 0 & c2 == 0]) * (1 - mean(c1)) + mean(a[c1 == 1 & c2 == 0]) * mean(c1))
# Author: Juha Karvanen/code: Tetiana Gorbach
# Date: 2024-05-17
# This code presents an example of a DAg with a trpdoor variable
# Load required library
library(mvtnorm)
library(bnlearn)
# Generate data -----------------------------------------------------------
# Set a seed for reproducibility
set.seed(292377111)
# Set the sample size
n <- 1000000
# Define confounders c1, c2 with a deterministic relationship
errors <- rmvnorm(n, sigma = diag(4))
# Generate confounders
u1 <- rnorm(n)
u2 <-  rnorm(n)
c1 <- rbinom(n, size = 1, prob = plogis(3 + u1 + u2)) #3 + u1 + u2 +   errors[, 1]
c2 <- rbinom(n, size = 1, prob = plogis(1 + u1 +  c1)) # 1 + u1 +  c1 + errors[, 2]
# Generate binary treatment that depends on c2
a <- rbinom(n, size = 1, prob = plogis(c1 + c2 + u1))
# Generate potential outcomes
y1 <- 4 + c1 + u2 + errors[, 3]
y0 <- 2 + c1 + u2 + errors[, 4]
# Generate observed outcome
y <- ifelse(a == 1, y1, y0)
# EY(1)
mean(y1)
# EY(1) estimate using the identification
(mean(y[c1 == 0 & c2 == 1 & a == 1]) * mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 1 & a == 1]) * mean(a[c1 == 1 & c2 == 1]) * mean(c1)) /
(mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) + mean(a[c1 == 1 & c2 == 1]) * mean(c1))
# EY(0)
mean(y0)
# EY(0) estimate using the identification
(mean(y[c1 == 0 & c2 == 1 & a == 0]) * mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 1 & a == 0]) * mean(a[c1 == 1 & c2 == 1]) * mean(c1)) /
(mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) + mean(a[c1 == 1 & c2 == 1]) * mean(c1))
(mean(y[c1 == 0 & c2 == 0 & a == 0]) * mean(a[c1 == 0 & c2 == 0]) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 0 & a == 0]) * mean(a[c1 == 1 & c2 == 0]) * mean(c1)) /
(mean(a[c1 == 0 & c2 == 0]) * (1 - mean(c1)) + mean(a[c1 == 1 & c2 == 0]) * mean(c1))
# EY(1)
mean(y1)
# EY(1) estimate using the identification
(mean(y[c1 == 0 & c2 == 1 & a == 1]) * mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 1 & a == 1]) * mean(a[c1 == 1 & c2 == 1]) * mean(c1)) /
(mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) + mean(a[c1 == 1 & c2 == 1]) * mean(c1))
# EY(0)
mean(y0)
# EY(0) estimate using the identification
(mean(y[c1 == 0 & c2 == 1 & a == 0]) * (1 - mean(a[c1 == 0 & c2 == 1]) )* (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 1 & a == 0]) * (1 - mean(a[c1 == 1 & c2 == 1]) )* mean(c1)) /
((1-mean(a[c1 == 0 & c2 == 1])) * (1 - mean(c1)) + (1-mean(a[c1 == 1 & c2 == 1])) * mean(c1))
(mean(y[c1 == 0 & c2 == 0 & a == 0]) * (1-mean(a[c1 == 0 & c2 == 0])) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 0 & a == 0]) * (1-mean(a[c1 == 1 & c2 == 0])) * mean(c1)) /
((1-mean(a[c1 == 0 & c2 == 0])) * (1 - mean(c1)) + (1-mean(a[c1 == 1 & c2 == 0])) * mean(c1))
mean(y0)
# EY(0) estimate using the identification
(mean(y[c1 == 0 & c2 == 1 & a == 0]) * (1 - mean(a[c1 == 0 & c2 == 1]))* (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 1 & a == 0]) * (1 - mean(a[c1 == 1 & c2 == 1]))* mean(c1)) /
((1-mean(a[c1 == 0 & c2 == 1])) * (1 - mean(c1)) + (1-mean(a[c1 == 1 & c2 == 1])) * mean(c1))
(mean(y[c1 == 0 & c2 == 0 & a == 0]) * (1-mean(a[c1 == 0 & c2 == 0])) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 0 & a == 0]) * (1-mean(a[c1 == 1 & c2 == 0])) * mean(c1)) /
((1-mean(a[c1 == 0 & c2 == 0])) * (1 - mean(c1)) + (1-mean(a[c1 == 1 & c2 == 0])) * mean(c1))
# EY(1)
mean(y1)
# EY(1) estimate using the identification
(mean(y[c1 == 0 & c2 == 1 & a == 1]) * mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 1 & a == 1]) * mean(a[c1 == 1 & c2 == 1]) * mean(c1)) /
(mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) + mean(a[c1 == 1 & c2 == 1]) * mean(c1))
(mean(y[c1 == 0 & c2 == 0 & a == 1]) * mean(a[c1 == 0 & c2 == 0]) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 0 & a == 1]) * mean(a[c1 == 1 & c2 == 0]) * mean(c1)) /
(mean(a[c1 == 0 & c2 == 0]) * (1 - mean(c1)) + mean(a[c1 == 1 & c2 == 0]) * mean(c1))
# Author: Juha Karvanen/code: Tetiana Gorbach
# Date: 2024-05-17
# This code presents an example of a DAg with a trpdoor variable
# Load required library
library(mvtnorm)
library(bnlearn)
# Generate data -----------------------------------------------------------
# Set a seed for reproducibility
set.seed(292377111)
# Set the sample size
n <- 1000000
# Define confounders c1, c2 with a deterministic relationship
errors <- rmvnorm(n, sigma = diag(4))
# Generate confounders
u1 <- rnorm(n)
u2 <-  rnorm(n)
c1 <- rbinom(n, size = 1, prob = plogis(3 + u1 + u2)) #3 + u1 + u2 +   errors[, 1]
c2 <- rbinom(n, size = 1, prob = plogis(1 + u1 +  c1)) # 1 + u1 +  c1 + errors[, 2]
# Generate binary treatment that depends on c2
a <- rbinom(n, size = 1, prob = plogis(c1 + c2 + u1))
# Generate potential outcomes
y1 <- 4 + c1 + u2 + errors[, 3]
y0 <- 2 + c1 + u2 + errors[, 4]
# Generate observed outcome
y <- ifelse(a == 1, y1, y0)
# EY(1)
mean(y1)
# EY(1) estimate using the identification
(mean(y[c1 == 0 & c2 == 1 & a == 1]) * mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 1 & a == 1]) * mean(a[c1 == 1 & c2 == 1]) * mean(c1)) /
(mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) + mean(a[c1 == 1 & c2 == 1]) * mean(c1))
(mean(y[c1 == 0 & c2 == 0 & a == 1]) * mean(a[c1 == 0 & c2 == 0]) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 0 & a == 1]) * mean(a[c1 == 1 & c2 == 0]) * mean(c1)) /
(mean(a[c1 == 0 & c2 == 0]) * (1 - mean(c1)) + mean(a[c1 == 1 & c2 == 0]) * mean(c1))
# Author: Juha Karvanen/code: Tetiana Gorbach
# Date: 2024-05-17
# This code presents an example of a DAg with a trpdoor variable
# Load required library
library(mvtnorm)
library(bnlearn)
# Helske's example --------------------------------------------------------
rm(list = ls())
set.seed(292377111)
# Set the sample size
n <- 1000000
v <- rbinom(n , size = 1, p = 0.5)
u <- rbinom(n , size = 1, p = 0.5)
c1 <- rbinom(n, size = 1, prob = 0.4*u + 0.4*v)
c2 <- rbinom(n, size = 1, prob = 0.4 + 0.4*c1)
a <- rbinom(n, size = 1, prob = 0.4*c2 + 0.4*v)
y <- rbinom(n, size = 1, prob = 0.4*a + 0.4*u)
# EY(1)
mean(y[a==1])  # ? is completely correct?
# EY(1) estimate using the identification
(mean(y[c1 == 0 & c2 == 1 & a == 1]) * mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 1 & a == 1]) * mean(a[c1 == 1 & c2 == 1]) * mean(c1)) /
(mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) + mean(a[c1 == 1 & c2 == 1]) * mean(c1))
# EY(0)
mean(y[a==0])
# EY(0) estimate using the identification
(mean(y[c1 == 0 & c2 == 1 & a == 0]) * mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 1 & a == 0]) * mean(a[c1 == 1 & c2 == 1]) * mean(c1)) /
(mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) + mean(a[c1 == 1 & c2 == 1]) * mean(c1))
(mean(y[c1 == 0 & c2 == 0 & a == 0]) * (1-mean(a[c1 == 0 & c2 == 0])) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 0 & a == 0]) * (1-mean(a[c1 == 1 & c2 == 0])) * mean(c1)) /
(mean(a[c1 == 0 & c2 == 0]) * (1 - mean(c1)) + mean(a[c1 == 1 & c2 == 0]) * mean(c1))
# EY(1)
mean(y[a==1])  # ? is completely correct?
# EY(1) estimate using the identification
(mean(y[c1 == 0 & c2 == 1 & a == 1]) * mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 1 & a == 1]) * mean(a[c1 == 1 & c2 == 1]) * mean(c1)) /
(mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) + mean(a[c1 == 1 & c2 == 1]) * mean(c1))
# EY(0)
mean(y[a==0])
# EY(0)
mean(y[a==0])
# EY(0) estimate using the identification
(mean(y[c1 == 0 & c2 == 1 & a == 0]) * mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 1 & a == 0]) * mean(a[c1 == 1 & c2 == 1]) * mean(c1)) /
((1-mean(a[c1 == 0 & c2 == 1])) * (1 - mean(c1)) + (1-mean(a[c1 == 1 & c2 == 1])) * mean(c1))
# EY(0) estimate using the identification
(mean(y[c1 == 0 & c2 == 1 & a == 0]) * (1-mean(a[c1 == 0 & c2 == 1])) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 1 & a == 0]) * (1- mean(a[c1 == 1 & c2 == 1])) * mean(c1)) /
((1-mean(a[c1 == 0 & c2 == 1])) * (1 - mean(c1)) + (1-mean(a[c1 == 1 & c2 == 1])) * mean(c1))
# EY(0)
mean(y[a==0])
# EY(0) estimate using the identification
(mean(y[c1 == 0 & c2 == 1 & a == 0]) * (1-mean(a[c1 == 0 & c2 == 1])) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 1 & a == 0]) * (1- mean(a[c1 == 1 & c2 == 1])) * mean(c1)) /
((1-mean(a[c1 == 0 & c2 == 1])) * (1 - mean(c1)) + (1-mean(a[c1 == 1 & c2 == 1])) * mean(c1))
(mean(y[c1 == 0 & c2 == 0 & a == 0]) * (1-mean(a[c1 == 0 & c2 == 0])) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 0 & a == 0]) * (1-mean(a[c1 == 1 & c2 == 0])) * mean(c1)) /
((1-mean(a[c1 == 0 & c2 == 0])) * (1 - mean(c1)) + (1-mean(a[c1 == 1 & c2 == 0])) * mean(c1))
sum(c1 == 0 & c2 == 1)
# Author: Juha Karvanen/code: Tetiana Gorbach
# Date: 2024-05-17
# This code presents an example of a DAg with a trpdoor variable
# Load required library
library(mvtnorm)
library(bnlearn)
# Generate data -----------------------------------------------------------
# Set a seed for reproducibility
set.seed(292377111)
# Set the sample size
n <- 1000000
# Define confounders c1, c2 with a deterministic relationship
errors <- rmvnorm(n, sigma = diag(4))
# Generate confounders
u1 <- rnorm(n)
u2 <-  rnorm(n)
c1 <- rbinom(n, size = 1, prob = plogis(3 + u1 + u2)) #3 + u1 + u2 +   errors[, 1]
c2 <- rbinom(n, size = 1, prob = plogis(1 + u1 +  c1)) # 1 + u1 +  c1 + errors[, 2]
# Generate binary treatment that depends on c2
a <- rbinom(n, size = 1, prob = plogis(c1 + c2 + u1))
# Generate potential outcomes
y1 <- 4 + c1 + u2 + errors[, 3]
y0 <- 2 + c1 + u2 + errors[, 4]
# Generate observed outcome
y <- ifelse(a == 1, y1, y0)
# EY(1)
mean(y1)
# EY(1) estimate using the identification
(mean(y[c1 == 0 & c2 == 1 & a == 1]) * mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 1 & a == 1]) * mean(a[c1 == 1 & c2 == 1]) * mean(c1)) /
(mean(a[c1 == 0 & c2 == 1]) * (1 - mean(c1)) + mean(a[c1 == 1 & c2 == 1]) * mean(c1))
(mean(y[c1 == 0 & c2 == 0 & a == 1]) * mean(a[c1 == 0 & c2 == 0]) * (1 - mean(c1)) +
mean(y[c1 == 1 & c2 == 0 & a == 1]) * mean(a[c1 == 1 & c2 == 0]) * mean(c1)) /
(mean(a[c1 == 0 & c2 == 0]) * (1 - mean(c1)) + mean(a[c1 == 1 & c2 == 0]) * mean(c1))
