y1 <- 4 + z11  + error[, 5]
y0 <- 2 + z01  + error[, 6]
# Average treatment effect is
mean(y1) - mean(y0)
# Observed  outcome
y <- ifelse(a == 1, y1, y0)
# Estimate the ATE --------------------------------------------------------
lm(y ~  a)
# Estimate the ATE
lm(y ~  z1 + z2 + a)
lm(yz1 ~    a)
lm(z1 ~    a)
# Generate data for a model with a cycle for which unconfoundness is fulfilled
# a->z1->y, z1->z2, z2->z1.
library(bnlearn)
# Generate data -----------------------------------------------------------
# Set a seed for reproducibility
library(MASS)
set.seed(123)
# Set the sample size
n <- 100000
alpha <-  0.1
# Define confounders c1, c2 with a cyclic relationship
error <- mvrnorm(n, rep(0,6), diag(6))
a <- rbinom(n, size = 1, prob = 0.5)
# z11 = a + alpha*z2 + error1
# z12 = alpha * z1 + error2. Substitute z2 into z1:
# z11 = a + alpha(alpha * z1 + error2) + error1
# z11 = a + alpha^2 * z1 + alpha*error2 + error1
# z11 = (a + alpha * error2 + error1)/(1 - alpha^2)
z11 <- (3+alpha*error[ ,2] + error[ ,1])/(1 - alpha^2)
z12 <-  alpha * z11 + error[,2]
z01 <- (alpha*error[ ,3] + error[ ,4])/(1 - alpha^2)
z02 <- alpha * z01 + error[,3]
# Observed mediator
z1 <- ifelse(a==1, z11, z01)
z2 <- ifelse(a==1, z12, z02)
y1 <- 4 + z11  + error[, 5]
y0 <- 2 + z01  + error[, 6]
# Average treatment effect is
mean(y1) - mean(y0)
# Observed  outcome
y <- ifelse(a == 1, y1, y0)
# Estimate the ATE
lm(y ~  a)
# Author: Juha Karvanen
# Date: 2023-11-08
# This code presents an example on multivariate dependency structures
# that cannot be presented as a DAG.
# Load required library
library(mvtnorm) # to simulate multivariate normal
library(ppcor) # to calculate partial correlations
library(bnlearn)
# Function to create a correlation matrix for multivariate normal
# distribution that follows the diamond dependency structure:
# A - B, A - C, B - D, C - D
# TODO: check the valid range for rho. Is it (-1,1) or something else?
sigmaf <- function(rho) {
a <- (sqrt(8 * rho^2 + 1) - 1) / 2
sigm <- matrix(c(1, rho, rho, a, rho, 1, a, rho, rho, a, 1, rho, a, rho, rho, 1), 4, 4)
return(sigm)
}
sigmaf
# Generate observed  4-variate confounders with a diamnond dependency structure
# Z1 - Z2, Z1 - Z3, Z3 - Z4, Z2 - Z4
covariance_diamond <- sigmaf(0.6)
covariance diamond
covariance_diamond
# Author: Juha Karvanen
# Date: 2023-11-08
# This code presents an example on multivariate dependency structures
# that cannot be presented as a DAG.
# Load required library
library(mvtnorm) # to simulate multivariate normal
library(ppcor) # to calculate partial correlations
library(bnlearn)
# Function to create a correlation matrix for multivariate normal
# distribution that follows the diamond dependency structure:
# A - B, A - C, B - D, C - D
# TODO: check the valid range for rho. Is it (-1,1) or something else?
sigmaf <- function(rho) {
a <- (sqrt(8 * rho^2 + 1) - 1) / 2
sigm <- matrix(c(1, rho, rho, a, rho, 1, a, rho, rho, a, 1, rho, a, rho, rho, 1), 4, 4)
return(sigm)
}
# We consider an example with nine variables.
# The clustered graph for the example can be presented as a DAG as follows
# A -> Y, Z -> A, Z -> Y
# Here A is a univariate treatment (binary) and
# Z = (Z1,Z2,Z3,Z4) and Y = (Y1,Y2,Y3,Y4) are four-variate variables (clusters)
# that have the diamond dependency structure. It is known (and can be checked)
# that this structure cannot be presented as a DAG.
# Generate data -----------------------------------------------------------
set.seed(2112023)
n <- 1000000
# Generate observed  4-variate confounders with a diamnond dependency structure
# Z1 - Z2, Z1 - Z3, Z3 - Z4, Z2 - Z4
covariance_diamond <- sigmaf(0.6)
confounders <- rmvnorm(n, sigma = covariance_diamond)
c1 <- confounders[, 1]
c2 <- confounders[, 2]
c3 <- confounders[, 3]
c4 <- confounders[, 4]
# Checking that the structure is indeed a diamond structure.
# In theory Z1 is independent of Z4 given Z2 and Z3:
ci.test(c1, c4, data.frame(confounders[,2], confounders[,3]))
print(covariance_diamond[c(1, 4), c(1, 4)] - covariance_diamond[c(1, 4), c(2, 3)] %*%
solve(covariance_diamond[c(2, 3), c(2, 3)]) %*% covariance_diamond[c(2, 3), c(1, 4)])
# Empirical (by default pcor conditions on all other variables)
print(pcor(confounders))
# We can see that Z has the diamond dependency structure.
# Treatment A depends on C1 and C2 via the logit link
# a <- 1 * (runif(n) > exp(c1 + c4) / (1 + exp(c1 + c4)))
a <- rbinom(n, size = 1, prob = plogis(c1 + c4))
y1 <- 4 + c1 + c4 + rnorm(n, 0, 1)
y0 <- 2 + c1 + c4 + rnorm(n, 0, 1)
# Average treatment effect is equal to total effect of Ey1 - Ey0 = 4 + Ec1 + EC0 - (2 - Ec1 - EC0) = 4  - 2 = 2
mean(y1) - mean(y0)
?plogis
errors <- rmvnorm(n, sigma = matrix(c(1, 0, 0,1, nrow = 2)))
errors <- rmvnorm(n, sigma = matrix(c(1, 0, 0,1), nrow = 2)))
errors <- rmvnorm(n, sigma = matrix(c(1, 0, 0,1), nrow = 2))
View(errors)
cor(errors)
errors <- rmvnorm(n, sigma = matrix(c(1, 0, 0,1), nrow = 2))
y1 <- 4 + c1 + c4 + errors[,1]
y0 <- 2 + c1 + c4 + errors[,2]
# Average treatment effect is equal to total effect of Ey1 - Ey0 = 4 + Ec1 + EC0 - (2 - Ec1 - EC0) = 4  - 2 = 2
mean(y1) - mean(y0)
y <- a*y1 + (1-a)*y0
lm(y~a+ c1+c2)
lm(y~a+ c1+c4)
lm(y~a+ c1+c4 + c2+c3)
ci.test(y0, a, confoundersc1)
ci.test(y0, a, c1)
ci.test(y0, a, as.data.frame(c1))
ci.test(as.numeric(y0), a, as.data.frame(c1))
ci.test(as.numeric(y0), as.numeric(a), as.data.frame(c1))
ci.test(as.numeric(y0), as.numeric(a), as.data.frame(c1, c2))
ci.test(as.numeric(y0), as.numeric(a), data.frame(c1, c2))
ci.test(as.numeric(y0), as.numeric(a), data.frame(c1, c4))
ci.test(as.numeric(y0), as.numeric(a), data.frame(c1, c2, c3, c4))
# Checking that the structure is indeed a diamond structure.
# In theory C1 is independent of C4 given C2 and C3:
ci.test(c1, c4, data.frame(confounders[,2], confounders[,3]))
# Author: Juha Karvanen
# Date: 2023-11-08
# This code presents an example on multivariate dependency structures
# that cannot be presented as a DAG.
# Load required library
library(mvtnorm) # to simulate multivariate normal
library(ppcor) # to calculate partial correlations
library(bnlearn)
# Function to create a correlation matrix for multivariate normal
# distribution that follows the diamond dependency structure:
# A - B, A - C, B - D, C - D
# TODO: check the valid range for rho. Is it (-1,1) or something else?
sigmaf <- function(rho) {
a <- (sqrt(8 * rho^2 + 1) - 1) / 2
sigm <- matrix(c(1, rho, rho, a, rho, 1, a, rho, rho, a, 1, rho, a, rho, rho, 1), 4, 4)
return(sigm)
}
# We consider an example with nine variables.
# The clustered graph for the example can be presented as a DAG as follows
# A -> Y, C -> A, C -> Y
# Here A is a univariate binary treatment, Y is the observed outcome,  and
# C = (C1,C2,C3,C4) is a four-variate variables (clusters)
# that have the diamond dependency structure. It is known (and can be checked)
# that this structure cannot be presented as a DAG.
# Generate data -----------------------------------------------------------
set.seed(2112023)
n <- 1000000
# Generate observed  4-variate confounders with a diamnond dependency structure
# C1 - C2, C1 - C3, C3 - C4, C2 - C4
covariance_diamond <- sigmaf(0.6)
confounders <- rmvnorm(n, sigma = covariance_diamond)
c1 <- confounders[, 1]
c2 <- confounders[, 2]
c3 <- confounders[, 3]
c4 <- confounders[, 4]
# Checking that the structure is indeed a diamond structure.
# In theory C1 is independent of C4 given C2 and C3:
ci.test(c1, c4, data.frame(confounders[,2], confounders[,3]))
print(covariance_diamond[c(1, 4), c(1, 4)] - covariance_diamond[c(1, 4), c(2, 3)] %*%
solve(covariance_diamond[c(2, 3), c(2, 3)]) %*% covariance_diamond[c(2, 3), c(1, 4)])
# Empirical (by default pcor conditions on all other variables)
print(pcor(confounders))
styler:::style_selection()
# Author: Juha Karvanen
# Date: 2023-11-08
# This code presents an example on multivariate dependency structures
# that cannot be presented as a DAG.
# Load required library
library(mvtnorm) # to simulate multivariate normal
library(ppcor) # to calculate partial correlations
library(bnlearn)
# Function to create a correlation matrix for multivariate normal
# distribution that follows the diamond dependency structure:
# A - B, A - C, B - D, C - D
# TODO: check the valid range for rho. Is it (-1,1) or something else?
sigmaf <- function(rho) {
a <- (sqrt(8 * rho^2 + 1) - 1) / 2
sigm <- matrix(c(1, rho, rho, a, rho, 1, a, rho, rho, a, 1, rho, a, rho, rho, 1), 4, 4)
return(sigm)
}
# We consider an example with nine variables.
# The clustered graph for the example can be presented as a DAG as follows
# A -> Y, C -> A, C -> Y
# Here A is a univariate binary treatment, Y is the observed outcome,  and
# C = (C1,C2,C3,C4) is a four-variate variables (clusters)
# that have the diamond dependency structure. It is known (and can be checked)
# that this structure cannot be presented as a DAG.
# Generate data -----------------------------------------------------------
set.seed(2112023)
n <- 1000000
# Generate observed  4-variate confounders with a diamnond dependency structure
# C1 - C2, C1 - C3, C3 - C4, C2 - C4
covariance_diamond <- sigmaf(0.6)
confounders <- rmvnorm(n, sigma = covariance_diamond)
c1 <- confounders[, 1]
c2 <- confounders[, 2]
c3 <- confounders[, 3]
c4 <- confounders[, 4]
# Checking that the structure is indeed a diamond structure.
# In theory C1 is independent of C4 given C2 and C3:
ci.test(c1, c4, data.frame(confounders[, 2], confounders[, 3]))
print(covariance_diamond[c(1, 4), c(1, 4)] - covariance_diamond[c(1, 4), c(2, 3)] %*%
solve(covariance_diamond[c(2, 3), c(2, 3)]) %*% covariance_diamond[c(2, 3), c(1, 4)])
# Empirical (by default pcor conditions on all other variables)
print(pcor(confounders))
# We can see that Z has the diamond dependency structure.
# Treatment A depends on C1 and C4 via the logit link
a <- rbinom(n, size = 1, prob = plogis(c1 + c4))
# Define potential outcomes
errors <- rmvnorm(n, sigma = matrix(c(1, 0, 0, 1), nrow = 2))
y1 <- 4 + c1 + c4 + errors[, 1]
y0 <- 2 + c1 + c4 + errors[, 2]
# Define the observed outcome
y <- ifelse(a == 1, y1, y0)
# Average treatment effect is equal to total effect of Ey1 - Ey0 = 4 + Ec1 + Ec4 - (2 - Ec1 - Ec4) = 4  - 2 = 2
mean(y1) - mean(y0)
# Check ignorability and estimate -----------------------------------------
# Conditional ignorability is fulfilled:
ci.test(as.numeric(y0), as.numeric(a), data.frame(c1, c4))
# Average causal effect can be consistenly estimated by a linear regression:
lm(y ~ a + c1 + c4)
# Generate data for a model with a cycle that includes
# a binary treatment, two confounders with a cyclic relationship, continuous outcome
# Graph is define by paths: c1 -> a, c2 -> treat, c1 -> c2, c2 -> c1, c1 -> Y, c2 -> Y, treat -> Y
library(bnlearn)
# Generate data -----------------------------------------------------------
# Set a seed for reproducibility
set.seed(123)
# Set the sample size
n <- 1000000
# Define confounders c1, c2 with a cyclic relationship
error1 <- rnorm(n, 0, 1)
error2 <- rnorm(n, 0, 1)
# c1 = 0.1*c2 + error1
# c2 = 0.1*c1 + error2
# in  a matrix form c = c*B + e. then c = e*(I-B)^(-1)
B <- matrix(c(0, 0.1, 0.1, 0), nrow = 2, byrow = T)
inverse_i_b <- solve(diag(2) - B) # (I-B)^-1
confouders <- cbind(error1, error2) %*% inverse_i_b # n*2 matrix of confounders c1, c2
c1 <- confouders[, 1]
c2 <- confouders[, 2]
# Generate binary treatment that depends on c1 and c2
a <- rbinom(n, size = 1, prob = plogis(c2))
y1 <- 4 + c2 + rnorm(n, 0, 1)
y0 <- 2 + c2 + rnorm(n, 0, 1)
# Average treatment effect is equal to total effect of Ey1 - Ey0 = 4 + Ec1 + EC0 - (2 - Ec1 - EC0) = 4  - 2 = 2
mean(y1) - mean(y0)
# Observed variables
y <- ifelse(a == 1, y1, y0)
# Estimate the ATE --------------------------------------------------------
lm(y ~ c1 + c2 + a)
ci.test(y1, as.numeric(a), data.frame(c1, c2)) # y1 is independent of T given c1,c2: weak unconfoundedness is fulfilled
ci.test(y1, as.numeric(a), data.frame(c1))
ci.test(y1, as.numeric(a), data.frame(c2))
# Generate data for a model with a cycle that includes
# a binary treatment, two confounders with a cyclic relationship, continuous outcome
# Graph is define by paths: c1 -> a, c2 -> treat, c1 -> c2, c2 -> c1, c1 -> Y, c2 -> Y, treat -> Y
library(bnlearn)
# Generate data -----------------------------------------------------------
# Set a seed for reproducibility
set.seed(123)
# Set the sample size
n <- 1000000
# Define confounders c1, c2 with a cyclic relationship
errors <- rmvnorm(n, sigma = diag(4))
error1 <- errors[, 1]
error2 <- errors[, 2]
# c1 = 0.1*c2 + error1
# c2 = 0.1*c1 + error2
# in  a matrix form c = c*B + e. then c = e*(I-B)^(-1)
B <- matrix(c(0, 0.1, 0.1, 0), nrow = 2, byrow = T)
inverse_i_b <- solve(diag(2) - B) # (I-B)^-1
confouders <- cbind(error1, error2) %*% inverse_i_b # n*2 matrix of confounders c1, c2
c1 <- confouders[, 1]
c2 <- confouders[, 2]
# Generate binary treatment that depends on c1 and c2
a <- rbinom(n, size = 1, prob = plogis(c2))
y1 <- 4 + c2 + rnorm(n, 0, 1)
y0 <- 2 + c2 + rnorm(n, 0, 1)
# Average treatment effect is equal to total effect of Ey1 - Ey0 = 4 + Ec1 + Ec2 - (2 - Ec1 - EC0) = 4  - 2 = 2
mean(y1) - mean(y0)
# Observed variables
y <- ifelse(a == 1, y1, y0)
# Estimate DAGs from the observed and potential outcomes data -------------
# Estimate a graph from the observed data
df <- as.data.frame(cbind(a, c1, c2, y))
# Estimate the Completed Partially Directed Acyclic Graph (CPDAG)
cpdag <- pc.stable(df)
# Plot the CPDAG to visualize the inferred causal relationships
plot(cpdag)
# Test for conditional independence of Y and A given C
ci.test(y, as.numeric(a), data.frame(c1, c2)) # Y depends on A given c1, c2
# Drawing a graph from the unobserved potential outcomes and the treatment variable
# undirected edges! but y1 is independent of T given c1,c2: weak unconfoundness is fulfilled
# Estimate a graph from the potential outcomes data
df2 <- as.data.frame(cbind(a, c1, c2, y1))
cpdag2 <- pc.stable(df2)
# Plot the graph
plot(cpdag2)
ci.test(y1, as.numeric(a), data.frame(c1, c2)) # y1 is independent of T given c1,c2: weak unconfoundedness is fulfilled
ci.test(y0, as.numeric(a), data.frame(c1, c2))
# Estimate the ATE --------------------------------------------------------
lm(y ~ c2 + a)
ci.test(y1, as.numeric(a), data.frame(c2)) # y1 is independent of T given c1,c2: weak unconfoundedness is fulfilled
ci.test(y0, as.numeric(a), data.frame(c2))
lm(y ~ c2 + c1 + a)
# Estimate the ATE --------------------------------------------------------
lm(y ~ c2 + a)
# Generate data for a model with a cycle that includes
# a binary treatment, two confounders with a cyclic relationship, continuous outcome
# Graph is define by paths: c1 -> a, c2 -> treat, c1 -> c2, c2 -> c1, c1 -> Y, c2 -> Y, treat -> Y
library(bnlearn)
# Generate data -----------------------------------------------------------
# Set a seed for reproducibility
set.seed(123)
# Set the sample size
n <- 1000000
# Define confounders c1, c2 with a cyclic relationship
errors <- rmvnorm(n, sigma = diag(4))
# Generate data for a model with a cycle that includes
# a binary treatment, two confounders with a cyclic relationship, continuous outcome
# Graph is define by paths: c1 -> a, c2 -> treat, c1 -> c2, c2 -> c1, c1 -> Y, c2 -> Y, treat -> Y
library(mvtnorm) # to simulate multivariate normal
library(bnlearn)
# Generate data -----------------------------------------------------------
# Set a seed for reproducibility
set.seed(123)
# Set the sample size
n <- 1000000
# Define confounders c1, c2 with a cyclic relationship
errors <- rmvnorm(n, sigma = diag(4))
error1 <- errors[, 1]
error2 <- errors[, 2]
# c1 = 0.1*c2 + error1
# c2 = 0.1*c1 + error2
# in  a matrix form c = c*B + e. then c = e*(I-B)^(-1)
B <- matrix(c(0, 0.1, 0.1, 0), nrow = 2, byrow = T)
inverse_i_b <- solve(diag(2) - B) # (I-B)^-1
confouders <- cbind(error1, error2) %*% inverse_i_b # n*2 matrix of confounders c1, c2
c1 <- confouders[, 1]
c2 <- confouders[, 2]
# Generate binary treatment that depends on c1 and c2
a <- rbinom(n, size = 1, prob = plogis(c2))
# Generate potential outcomes
y1 <- 4 + c2 + errors[, 3]
y0 <- 2 + c2 + errors[, 4]
# Generate observed outcome
y <- ifelse(a == 1, y1, y0)
# Average treatment effect is equal to total effect of Ey1 - Ey0 = 4 + Ec1 + Ec2 - (2 - Ec1 - EC0) = 4  - 2 = 2
mean(y1) - mean(y0)
# Estimate DAGs from the observed and potential outcomes data -------------
# Estimate a graph from the observed data
df <- as.data.frame(cbind(a, c1, c2, y))
# Estimate the Completed Partially Directed Acyclic Graph (CPDAG)
cpdag <- pc.stable(df)
# Plot the CPDAG to visualize the inferred causal relationships
plot(cpdag)
# Test for conditional independence of Y and A given C
ci.test(y, as.numeric(a), data.frame(c2)) # Y depends on A given  c2
# Test for conditional independence of Y and A given C
ci.test(y, as.numeric(a), data.frame(c1,c2)) # Y depends on A given  c2
?ci.test
# Estimate the ATE --------------------------------------------------------
lm(y ~ c2 + a)
# Estimate the ATE --------------------------------------------------------
lm(y ~ c2 + a)
# Author: Ingeborg Waernbaum
# Date: 2023-11-08
# This code presents an example on multivariate dependency structures with a
# deterministic relationships between the variables that cannot be presented as a DAG.
# Generate data with a binary treatment, continuous first mediator and dichotomized subsequent mediator
# no confounding
# Load required library
library(bnlearn)
# Generate data -----------------------------------------------------------
# Set a seed for reproducibility
set.seed(2911)
# Set the sample size
n <- 1000000
# Generate confounders
c1 <- rnorm(n, 3, 1)
c2 <- ifelse(c1 < 3, 0, 2)
# Generate binary treatment that depends on c2
a <- rbinom(n, size = 1, prob = plogis(c2))
table(a)
# Author: Ingeborg Waernbaum
# Date: 2023-11-08
# This code presents an example on multivariate dependency structures with a
# deterministic relationships between the variables that cannot be presented as a DAG.
# Generate data with a binary treatment, continuous first mediator and dichotomized subsequent mediator
# no confounding
# Load required library
library(bnlearn)
# Generate data -----------------------------------------------------------
# Set a seed for reproducibility
set.seed(2911)
# Set the sample size
n <- 1000000
errors <- rmvnorm(n, sigma = diag(3))
# Generate confounders
c1 <- 3 + errors[, 1]
c2 <- ifelse(c1 < 3, 0, 2)
# Generate binary treatment that depends on c2
a <- rbinom(n, size = 1, prob = plogis(c2))
# Generate potential outcomes
y1 <- 4 + c2 + errors[, 2]
y0 <- 2 + c2 + errors[, 3]
# Generate observed outcome
y <- ifelse(a == 1, y1, y0)
# Average treatment effect is equal to total effect of Ey1 - Ey0 = 4 + Ec1 - (2 + Ec2) = 4  - 2  = 2
mean(y1) - mean(y0)
ci.test(y0, as.numeric(a), data.frame(c2)) # y0 is independent of a given c2: weak unconfoundedness is fulfilled
ci.test(y1, as.numeric(a), data.frame(c2)) # y1 is independent of a given c2: weak unconfoundedness is fulfilled
# Estimate the ATE --------------------------------------------------------
lm(y ~ c2 + a)
# Estimate DAGs from the observed and potential outcomes data -------------
# Estimate a graph from the observed data
df <- as.data.frame(cbind(a, c1, c2, y))
cpdag <- pc.stable(df)
# Plot the graph to visualize the inferred causal relationships
plot(cpdag)
# Test for conditional independence of Y and Z given V
ci.test(y, z , v) # does this show something?
# Test for conditional independence of Y and Z given V
ci.test(y, c1, c2 , v) # does this show something?
# Drawing a graphfrom the unobserved potential outcomes and the treatment variable (corresponding to the SWIG)
# not a valid SWIG due to the deterministic function v1 of z1!
df2 <- as.data.frame(cbind(a, c1, c2, y1))
cpdag2 <- pc.stable(df2)
# Plot the graph to visualize the inferred causal relationships
plot(cpdag2)
# Check ignorability and estimate -----------------------------------------
ci.test(y0, as.numeric(a), data.frame(c2)) # y0 is independent of a given c2: weak unconfoundedness is fulfilled
ci.test(y1, as.numeric(a), data.frame(c2)) # y1 is independent of a given c2: weak unconfoundedness is fulfilled
c2 <- ifelse(3 < 3, 0, 2)
c2
ifelse(3> 3, 0, 2)
ifelse(3< 3, 0, 2)
?ifelse
ifelse(3<= 3, 0, 2)
ifelse(3> 3, 0, 2)
2*as.numeric(3 >= 3)
2*as.numeric(2 >= 3)
# Author: Ingeborg Waernbaum
# Date: 2023-11-08
# This code presents an example on multivariate dependency structures with a
# deterministic relationships between the variables that cannot be presented as a DAG.
# Generate data with a binary treatment, continuous first mediator and dichotomized subsequent mediator
# no confounding
# Load required library
library(bnlearn)
# Generate data -----------------------------------------------------------
# Set a seed for reproducibility
set.seed(2911)
# Set the sample size
n <- 1000000
# Define confounders c1, c2 with a deterministic relationship
errors <- rmvnorm(n, sigma = diag(3))
# Generate confounders
c1 <- 3 + errors[, 1]
c2 <- 2*as.numeric(c1 >= 3)
# Generate binary treatment that depends on c2
a <- rbinom(n, size = 1, prob = plogis(c2))
# Generate potential outcomes
y1 <- 4 + c2 + errors[, 2]
y0 <- 2 + c2 + errors[, 3]
# Generate observed outcome
y <- ifelse(a == 1, y1, y0)
# Average treatment effect is equal to total effect of Ey1 - Ey0 = 4 + Ec1 - (2 + Ec2) = 4 - 2  = 2
mean(y1) - mean(y0)
# Estimate DAGs from the observed and potential outcomes data -------------
# Estimate a graph from the observed data
df <- as.data.frame(cbind(a, c1, c2, y))
cpdag <- pc.stable(df)
# Plot the graph to visualize the inferred causal relationships
plot(cpdag)
# Drawing a graph from the unobserved potential outcomes and the treatment variable (corresponding to the SWIG)
# not a valid SWIG due to the deterministic function c2 of c1!
df2 <- as.data.frame(cbind(a, c1, c2, y1))
cpdag2 <- pc.stable(df2)
# Plot the graph to visualize the inferred causal relationships
plot(cpdag2)
# Check ignorability ------------------------------------------------------
ci.test(y0, as.numeric(a), data.frame(c2)) # y0 is independent of a given c2: weak unconfoundedness is fulfilled
ci.test(y1, as.numeric(a), data.frame(c2)) # y1 is independent of a given c2: weak unconfoundedness is fulfilled
# Average causal effect can be consistently estimated by a linear regression: --------
lm(y ~ a + c2)
